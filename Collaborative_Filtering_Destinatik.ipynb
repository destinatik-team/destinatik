{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaPxTWiFR5vN"
      },
      "source": [
        "# Collaborative Filtering for Destination Recommendations\n",
        "\n",
        "All the steps bellow based on: https://keras.io/examples/structured_data/collaborative_filtering_movielens/\n",
        "\n",
        "Note: please do not make any changes or run into this code! If you want to try this code, do make a copy to your drive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rt-BWwTh-_iq"
      },
      "source": [
        "## Installations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gY2MEq7I7VAI",
        "outputId": "f45da1d3-d835-462c-d720-6179b8b2e9eb"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "49wI6Ce4MMMh"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-06-10 01:43:18.942352: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-06-10 01:43:19.408351: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-06-10 01:43:20.993307: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# from zipfile import ZipFile\n",
        "\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras import ops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "cj319MA65n-h",
        "outputId": "3d0a78d1-0d1e-4b11-97e6-10ab3358f00e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0ea56f18-8a0b-42f3-870b-e0d3fd6e72c1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0ea56f18-8a0b-42f3-870b-e0d3fd6e72c1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving tourism_rating.csv to tourism_rating.csv\n",
            "Saving tourism_with_id.csv to tourism_with_id.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osAcg-MoNuAY"
      },
      "source": [
        "## Cleaning Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "rates = pd.read_csv('./datasets/tourism_rating.csv')\n",
        "places = pd.read_csv('./datasets/tourism_with_id.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aSnPIA_Nsx4"
      },
      "outputs": [],
      "source": [
        "rates = pd.read_csv('/content/tourism_rating.csv')\n",
        "places = pd.read_csv('/content/tourism_with_id.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "IxIHgvxV40i2",
        "outputId": "8e45e7d8-94ce-4afd-e909-b3581a544ed8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User_Id</th>\n",
              "      <th>Place_Id</th>\n",
              "      <th>Place_Ratings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>179</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>344</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>373</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>101</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>300</td>\n",
              "      <td>425</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>300</td>\n",
              "      <td>64</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>300</td>\n",
              "      <td>311</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>300</td>\n",
              "      <td>279</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>300</td>\n",
              "      <td>163</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      User_Id  Place_Id  Place_Ratings\n",
              "0           1       179              3\n",
              "1           1       344              2\n",
              "2           1         5              5\n",
              "3           1       373              3\n",
              "4           1       101              4\n",
              "...       ...       ...            ...\n",
              "9995      300       425              2\n",
              "9996      300        64              4\n",
              "9997      300       311              3\n",
              "9998      300       279              4\n",
              "9999      300       163              2\n",
              "\n",
              "[10000 rows x 3 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "wYKaKi9j_o0z",
        "outputId": "8340b4e2-c1f1-4161-f611-035231d74caa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jumlah duplikasi:  79\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User_Id</th>\n",
              "      <th>Place_Id</th>\n",
              "      <th>Place_Ratings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>151.292700</td>\n",
              "      <td>219.416400</td>\n",
              "      <td>3.066500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>86.137374</td>\n",
              "      <td>126.228335</td>\n",
              "      <td>1.379952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>77.000000</td>\n",
              "      <td>108.750000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>151.000000</td>\n",
              "      <td>220.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>226.000000</td>\n",
              "      <td>329.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>300.000000</td>\n",
              "      <td>437.000000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            User_Id      Place_Id  Place_Ratings\n",
              "count  10000.000000  10000.000000   10000.000000\n",
              "mean     151.292700    219.416400       3.066500\n",
              "std       86.137374    126.228335       1.379952\n",
              "min        1.000000      1.000000       1.000000\n",
              "25%       77.000000    108.750000       2.000000\n",
              "50%      151.000000    220.000000       3.000000\n",
              "75%      226.000000    329.000000       4.000000\n",
              "max      300.000000    437.000000       5.000000"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Jumlah duplikasi: \", rates.duplicated().sum())\n",
        "rates.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uvoCKXh_tXP",
        "outputId": "87df5b79-22ec-46e1-a156-2c8296807c8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 9921 entries, 0 to 9999\n",
            "Data columns (total 3 columns):\n",
            " #   Column         Non-Null Count  Dtype\n",
            "---  ------         --------------  -----\n",
            " 0   User_Id        9921 non-null   int64\n",
            " 1   Place_Id       9921 non-null   int64\n",
            " 2   Place_Ratings  9921 non-null   int64\n",
            "dtypes: int64(3)\n",
            "memory usage: 310.0 KB\n"
          ]
        }
      ],
      "source": [
        "rates = rates.drop_duplicates()\n",
        "rates.reset_index(drop=True)\n",
        "\n",
        "rates.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "h1LaZKrgOHyx",
        "outputId": "18462d07-0eba-450a-c7e4-c0bb326eeae9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Place_Id</th>\n",
              "      <th>Place_Name</th>\n",
              "      <th>Description</th>\n",
              "      <th>Category</th>\n",
              "      <th>City</th>\n",
              "      <th>Price</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Time_Minutes</th>\n",
              "      <th>Coordinate</th>\n",
              "      <th>Lat</th>\n",
              "      <th>Long</th>\n",
              "      <th>Unnamed: 11</th>\n",
              "      <th>Unnamed: 12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Monumen Nasional</td>\n",
              "      <td>Monumen Nasional atau yang populer disingkat d...</td>\n",
              "      <td>Budaya</td>\n",
              "      <td>Jakarta</td>\n",
              "      <td>20000</td>\n",
              "      <td>4.6</td>\n",
              "      <td>15.0</td>\n",
              "      <td>{'lat': -6.1753924, 'lng': 106.8271528}</td>\n",
              "      <td>-6.175392</td>\n",
              "      <td>106.827153</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Kota Tua</td>\n",
              "      <td>Kota tua di Jakarta, yang juga bernama Kota Tu...</td>\n",
              "      <td>Budaya</td>\n",
              "      <td>Jakarta</td>\n",
              "      <td>0</td>\n",
              "      <td>4.6</td>\n",
              "      <td>90.0</td>\n",
              "      <td>{'lat': -6.137644799999999, 'lng': 106.8171245}</td>\n",
              "      <td>-6.137645</td>\n",
              "      <td>106.817125</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Dunia Fantasi</td>\n",
              "      <td>Dunia Fantasi atau disebut juga Dufan adalah t...</td>\n",
              "      <td>Taman Hiburan</td>\n",
              "      <td>Jakarta</td>\n",
              "      <td>270000</td>\n",
              "      <td>4.6</td>\n",
              "      <td>360.0</td>\n",
              "      <td>{'lat': -6.125312399999999, 'lng': 106.8335377}</td>\n",
              "      <td>-6.125312</td>\n",
              "      <td>106.833538</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Taman Mini Indonesia Indah (TMII)</td>\n",
              "      <td>Taman Mini Indonesia Indah merupakan suatu kaw...</td>\n",
              "      <td>Taman Hiburan</td>\n",
              "      <td>Jakarta</td>\n",
              "      <td>10000</td>\n",
              "      <td>4.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'lat': -6.302445899999999, 'lng': 106.8951559}</td>\n",
              "      <td>-6.302446</td>\n",
              "      <td>106.895156</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Atlantis Water Adventure</td>\n",
              "      <td>Atlantis Water Adventure atau dikenal dengan A...</td>\n",
              "      <td>Taman Hiburan</td>\n",
              "      <td>Jakarta</td>\n",
              "      <td>94000</td>\n",
              "      <td>4.5</td>\n",
              "      <td>60.0</td>\n",
              "      <td>{'lat': -6.12419, 'lng': 106.839134}</td>\n",
              "      <td>-6.124190</td>\n",
              "      <td>106.839134</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>432</th>\n",
              "      <td>433</td>\n",
              "      <td>Museum Mpu Tantular</td>\n",
              "      <td>Museum Negeri Mpu Tantular adalah sebuah museu...</td>\n",
              "      <td>Budaya</td>\n",
              "      <td>Surabaya</td>\n",
              "      <td>2000</td>\n",
              "      <td>4.4</td>\n",
              "      <td>45.0</td>\n",
              "      <td>{'lat': -7.4338593, 'lng': 112.7199058}</td>\n",
              "      <td>-7.433859</td>\n",
              "      <td>112.719906</td>\n",
              "      <td>NaN</td>\n",
              "      <td>433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>433</th>\n",
              "      <td>434</td>\n",
              "      <td>Taman Bungkul</td>\n",
              "      <td>Taman Bungkul adalah taman wisata kota yang te...</td>\n",
              "      <td>Taman Hiburan</td>\n",
              "      <td>Surabaya</td>\n",
              "      <td>0</td>\n",
              "      <td>4.6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'lat': -7.291346799999999, 'lng': 112.7398218}</td>\n",
              "      <td>-7.291347</td>\n",
              "      <td>112.739822</td>\n",
              "      <td>NaN</td>\n",
              "      <td>434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>434</th>\n",
              "      <td>435</td>\n",
              "      <td>Taman Air Mancur Menari Kenjeran</td>\n",
              "      <td>Air mancur menari atau dancing fountain juga a...</td>\n",
              "      <td>Taman Hiburan</td>\n",
              "      <td>Surabaya</td>\n",
              "      <td>0</td>\n",
              "      <td>4.4</td>\n",
              "      <td>45.0</td>\n",
              "      <td>{'lat': -7.2752955, 'lng': 112.7549381}</td>\n",
              "      <td>-7.275296</td>\n",
              "      <td>112.754938</td>\n",
              "      <td>NaN</td>\n",
              "      <td>435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435</th>\n",
              "      <td>436</td>\n",
              "      <td>Taman Flora Bratang Surabaya</td>\n",
              "      <td>Taman Flora adalah salah satu taman kota di Su...</td>\n",
              "      <td>Taman Hiburan</td>\n",
              "      <td>Surabaya</td>\n",
              "      <td>0</td>\n",
              "      <td>4.6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'lat': -7.294330299999999, 'lng': 112.7617534}</td>\n",
              "      <td>-7.294330</td>\n",
              "      <td>112.761753</td>\n",
              "      <td>NaN</td>\n",
              "      <td>436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>436</th>\n",
              "      <td>437</td>\n",
              "      <td>Gereja Perawan Maria Tak Berdosa Surabaya</td>\n",
              "      <td>Gereja Katolik Kelahiran Santa Perawan Maria m...</td>\n",
              "      <td>Tempat Ibadah</td>\n",
              "      <td>Surabaya</td>\n",
              "      <td>10000</td>\n",
              "      <td>4.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'lat': -7.2420758, 'lng': 112.7368158}</td>\n",
              "      <td>-7.242076</td>\n",
              "      <td>112.736816</td>\n",
              "      <td>NaN</td>\n",
              "      <td>437</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>437 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Place_Id                                 Place_Name  \\\n",
              "0           1                           Monumen Nasional   \n",
              "1           2                                   Kota Tua   \n",
              "2           3                              Dunia Fantasi   \n",
              "3           4          Taman Mini Indonesia Indah (TMII)   \n",
              "4           5                   Atlantis Water Adventure   \n",
              "..        ...                                        ...   \n",
              "432       433                        Museum Mpu Tantular   \n",
              "433       434                              Taman Bungkul   \n",
              "434       435           Taman Air Mancur Menari Kenjeran   \n",
              "435       436               Taman Flora Bratang Surabaya   \n",
              "436       437  Gereja Perawan Maria Tak Berdosa Surabaya   \n",
              "\n",
              "                                           Description       Category  \\\n",
              "0    Monumen Nasional atau yang populer disingkat d...         Budaya   \n",
              "1    Kota tua di Jakarta, yang juga bernama Kota Tu...         Budaya   \n",
              "2    Dunia Fantasi atau disebut juga Dufan adalah t...  Taman Hiburan   \n",
              "3    Taman Mini Indonesia Indah merupakan suatu kaw...  Taman Hiburan   \n",
              "4    Atlantis Water Adventure atau dikenal dengan A...  Taman Hiburan   \n",
              "..                                                 ...            ...   \n",
              "432  Museum Negeri Mpu Tantular adalah sebuah museu...         Budaya   \n",
              "433  Taman Bungkul adalah taman wisata kota yang te...  Taman Hiburan   \n",
              "434  Air mancur menari atau dancing fountain juga a...  Taman Hiburan   \n",
              "435  Taman Flora adalah salah satu taman kota di Su...  Taman Hiburan   \n",
              "436  Gereja Katolik Kelahiran Santa Perawan Maria m...  Tempat Ibadah   \n",
              "\n",
              "         City   Price  Rating  Time_Minutes  \\\n",
              "0     Jakarta   20000     4.6          15.0   \n",
              "1     Jakarta       0     4.6          90.0   \n",
              "2     Jakarta  270000     4.6         360.0   \n",
              "3     Jakarta   10000     4.5           NaN   \n",
              "4     Jakarta   94000     4.5          60.0   \n",
              "..        ...     ...     ...           ...   \n",
              "432  Surabaya    2000     4.4          45.0   \n",
              "433  Surabaya       0     4.6           NaN   \n",
              "434  Surabaya       0     4.4          45.0   \n",
              "435  Surabaya       0     4.6           NaN   \n",
              "436  Surabaya   10000     4.8           NaN   \n",
              "\n",
              "                                          Coordinate       Lat        Long  \\\n",
              "0            {'lat': -6.1753924, 'lng': 106.8271528} -6.175392  106.827153   \n",
              "1    {'lat': -6.137644799999999, 'lng': 106.8171245} -6.137645  106.817125   \n",
              "2    {'lat': -6.125312399999999, 'lng': 106.8335377} -6.125312  106.833538   \n",
              "3    {'lat': -6.302445899999999, 'lng': 106.8951559} -6.302446  106.895156   \n",
              "4               {'lat': -6.12419, 'lng': 106.839134} -6.124190  106.839134   \n",
              "..                                               ...       ...         ...   \n",
              "432          {'lat': -7.4338593, 'lng': 112.7199058} -7.433859  112.719906   \n",
              "433  {'lat': -7.291346799999999, 'lng': 112.7398218} -7.291347  112.739822   \n",
              "434          {'lat': -7.2752955, 'lng': 112.7549381} -7.275296  112.754938   \n",
              "435  {'lat': -7.294330299999999, 'lng': 112.7617534} -7.294330  112.761753   \n",
              "436          {'lat': -7.2420758, 'lng': 112.7368158} -7.242076  112.736816   \n",
              "\n",
              "     Unnamed: 11  Unnamed: 12  \n",
              "0            NaN            1  \n",
              "1            NaN            2  \n",
              "2            NaN            3  \n",
              "3            NaN            4  \n",
              "4            NaN            5  \n",
              "..           ...          ...  \n",
              "432          NaN          433  \n",
              "433          NaN          434  \n",
              "434          NaN          435  \n",
              "435          NaN          436  \n",
              "436          NaN          437  \n",
              "\n",
              "[437 rows x 13 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "places"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "8gneI5li3iRl",
        "outputId": "bde399c7-8879-48a6-d20b-0399beb09455"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Place_Id</th>\n",
              "      <th>Place_Name</th>\n",
              "      <th>Description</th>\n",
              "      <th>Category</th>\n",
              "      <th>City</th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Monumen Nasional</td>\n",
              "      <td>Monumen Nasional atau yang populer disingkat d...</td>\n",
              "      <td>Budaya</td>\n",
              "      <td>Jakarta</td>\n",
              "      <td>20000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Kota Tua</td>\n",
              "      <td>Kota tua di Jakarta, yang juga bernama Kota Tu...</td>\n",
              "      <td>Budaya</td>\n",
              "      <td>Jakarta</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Dunia Fantasi</td>\n",
              "      <td>Dunia Fantasi atau disebut juga Dufan adalah t...</td>\n",
              "      <td>Taman Hiburan</td>\n",
              "      <td>Jakarta</td>\n",
              "      <td>270000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Taman Mini Indonesia Indah (TMII)</td>\n",
              "      <td>Taman Mini Indonesia Indah merupakan suatu kaw...</td>\n",
              "      <td>Taman Hiburan</td>\n",
              "      <td>Jakarta</td>\n",
              "      <td>10000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Atlantis Water Adventure</td>\n",
              "      <td>Atlantis Water Adventure atau dikenal dengan A...</td>\n",
              "      <td>Taman Hiburan</td>\n",
              "      <td>Jakarta</td>\n",
              "      <td>94000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>432</th>\n",
              "      <td>433</td>\n",
              "      <td>Museum Mpu Tantular</td>\n",
              "      <td>Museum Negeri Mpu Tantular adalah sebuah museu...</td>\n",
              "      <td>Budaya</td>\n",
              "      <td>Surabaya</td>\n",
              "      <td>2000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>433</th>\n",
              "      <td>434</td>\n",
              "      <td>Taman Bungkul</td>\n",
              "      <td>Taman Bungkul adalah taman wisata kota yang te...</td>\n",
              "      <td>Taman Hiburan</td>\n",
              "      <td>Surabaya</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>434</th>\n",
              "      <td>435</td>\n",
              "      <td>Taman Air Mancur Menari Kenjeran</td>\n",
              "      <td>Air mancur menari atau dancing fountain juga a...</td>\n",
              "      <td>Taman Hiburan</td>\n",
              "      <td>Surabaya</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435</th>\n",
              "      <td>436</td>\n",
              "      <td>Taman Flora Bratang Surabaya</td>\n",
              "      <td>Taman Flora adalah salah satu taman kota di Su...</td>\n",
              "      <td>Taman Hiburan</td>\n",
              "      <td>Surabaya</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>436</th>\n",
              "      <td>437</td>\n",
              "      <td>Gereja Perawan Maria Tak Berdosa Surabaya</td>\n",
              "      <td>Gereja Katolik Kelahiran Santa Perawan Maria m...</td>\n",
              "      <td>Tempat Ibadah</td>\n",
              "      <td>Surabaya</td>\n",
              "      <td>10000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>437 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Place_Id                                 Place_Name  \\\n",
              "0           1                           Monumen Nasional   \n",
              "1           2                                   Kota Tua   \n",
              "2           3                              Dunia Fantasi   \n",
              "3           4          Taman Mini Indonesia Indah (TMII)   \n",
              "4           5                   Atlantis Water Adventure   \n",
              "..        ...                                        ...   \n",
              "432       433                        Museum Mpu Tantular   \n",
              "433       434                              Taman Bungkul   \n",
              "434       435           Taman Air Mancur Menari Kenjeran   \n",
              "435       436               Taman Flora Bratang Surabaya   \n",
              "436       437  Gereja Perawan Maria Tak Berdosa Surabaya   \n",
              "\n",
              "                                           Description       Category  \\\n",
              "0    Monumen Nasional atau yang populer disingkat d...         Budaya   \n",
              "1    Kota tua di Jakarta, yang juga bernama Kota Tu...         Budaya   \n",
              "2    Dunia Fantasi atau disebut juga Dufan adalah t...  Taman Hiburan   \n",
              "3    Taman Mini Indonesia Indah merupakan suatu kaw...  Taman Hiburan   \n",
              "4    Atlantis Water Adventure atau dikenal dengan A...  Taman Hiburan   \n",
              "..                                                 ...            ...   \n",
              "432  Museum Negeri Mpu Tantular adalah sebuah museu...         Budaya   \n",
              "433  Taman Bungkul adalah taman wisata kota yang te...  Taman Hiburan   \n",
              "434  Air mancur menari atau dancing fountain juga a...  Taman Hiburan   \n",
              "435  Taman Flora adalah salah satu taman kota di Su...  Taman Hiburan   \n",
              "436  Gereja Katolik Kelahiran Santa Perawan Maria m...  Tempat Ibadah   \n",
              "\n",
              "         City   Price  \n",
              "0     Jakarta   20000  \n",
              "1     Jakarta       0  \n",
              "2     Jakarta  270000  \n",
              "3     Jakarta   10000  \n",
              "4     Jakarta   94000  \n",
              "..        ...     ...  \n",
              "432  Surabaya    2000  \n",
              "433  Surabaya       0  \n",
              "434  Surabaya       0  \n",
              "435  Surabaya       0  \n",
              "436  Surabaya   10000  \n",
              "\n",
              "[437 rows x 6 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "places = places.drop(columns=[\n",
        "                              'Coordinate',\n",
        "                              'Unnamed: 11',\n",
        "                              'Unnamed: 12',\n",
        "                              'Time_Minutes',\n",
        "                              'Long',\n",
        "                              'Lat',\n",
        "                              'Rating'])\n",
        "places"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-IvBfcnr_Vo"
      },
      "source": [
        "## Merging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hAyZhTS8sCsY",
        "outputId": "98029e6b-3a68-4aef-fa5c-6784111475b3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User_Id</th>\n",
              "      <th>Place_Id</th>\n",
              "      <th>Place_Ratings</th>\n",
              "      <th>Place_Name</th>\n",
              "      <th>Description</th>\n",
              "      <th>Category</th>\n",
              "      <th>City</th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>179</td>\n",
              "      <td>3</td>\n",
              "      <td>Candi Ratu Boko</td>\n",
              "      <td>Situs Ratu Baka atau Candi Boko (Hanacaraka:ꦕꦤ...</td>\n",
              "      <td>Budaya</td>\n",
              "      <td>Yogyakarta</td>\n",
              "      <td>75000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>344</td>\n",
              "      <td>2</td>\n",
              "      <td>Pantai Marina</td>\n",
              "      <td>Pantai Marina (bahasa Jawa: ꦥꦱꦶꦱꦶꦂ​ꦩꦫꦶꦤ, trans...</td>\n",
              "      <td>Bahari</td>\n",
              "      <td>Semarang</td>\n",
              "      <td>3000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>Atlantis Water Adventure</td>\n",
              "      <td>Atlantis Water Adventure atau dikenal dengan A...</td>\n",
              "      <td>Taman Hiburan</td>\n",
              "      <td>Jakarta</td>\n",
              "      <td>94000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>373</td>\n",
              "      <td>3</td>\n",
              "      <td>Museum Kereta Ambarawa</td>\n",
              "      <td>Museum Kereta Api Ambarawa (bahasa Inggris: In...</td>\n",
              "      <td>Budaya</td>\n",
              "      <td>Semarang</td>\n",
              "      <td>10000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>101</td>\n",
              "      <td>4</td>\n",
              "      <td>Kampung Wisata Sosro Menduran</td>\n",
              "      <td>Kampung wisata Sosromenduran merupakan kampung...</td>\n",
              "      <td>Budaya</td>\n",
              "      <td>Yogyakarta</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9916</th>\n",
              "      <td>300</td>\n",
              "      <td>425</td>\n",
              "      <td>2</td>\n",
              "      <td>Waterpark Kenjeran Surabaya</td>\n",
              "      <td>Waterpark Kenjeran Surabaya merupakan wisata k...</td>\n",
              "      <td>Taman Hiburan</td>\n",
              "      <td>Surabaya</td>\n",
              "      <td>35000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9917</th>\n",
              "      <td>300</td>\n",
              "      <td>64</td>\n",
              "      <td>4</td>\n",
              "      <td>Museum Sasmita Loka Ahmad Yani</td>\n",
              "      <td>Museum Sasmita Loka Ahmad Yani adalah salah sa...</td>\n",
              "      <td>Budaya</td>\n",
              "      <td>Jakarta</td>\n",
              "      <td>2000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9918</th>\n",
              "      <td>300</td>\n",
              "      <td>311</td>\n",
              "      <td>3</td>\n",
              "      <td>The Lodge Maribaya</td>\n",
              "      <td>The Lodge Maribaya adalah salah satu tempat wi...</td>\n",
              "      <td>Cagar Alam</td>\n",
              "      <td>Bandung</td>\n",
              "      <td>25000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9919</th>\n",
              "      <td>300</td>\n",
              "      <td>279</td>\n",
              "      <td>4</td>\n",
              "      <td>Masjid Agung Trans Studio Bandung</td>\n",
              "      <td>Masjid Agung Trans Studio Bandung (TSB) berdir...</td>\n",
              "      <td>Tempat Ibadah</td>\n",
              "      <td>Bandung</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9920</th>\n",
              "      <td>300</td>\n",
              "      <td>163</td>\n",
              "      <td>2</td>\n",
              "      <td>Watu Mabur Mangunan</td>\n",
              "      <td>Kawasan Tebing Watu Mabur ini terbilang belum ...</td>\n",
              "      <td>Cagar Alam</td>\n",
              "      <td>Yogyakarta</td>\n",
              "      <td>2500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9921 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      User_Id  Place_Id  Place_Ratings                         Place_Name  \\\n",
              "0           1       179              3                    Candi Ratu Boko   \n",
              "1           1       344              2                      Pantai Marina   \n",
              "2           1         5              5           Atlantis Water Adventure   \n",
              "3           1       373              3             Museum Kereta Ambarawa   \n",
              "4           1       101              4      Kampung Wisata Sosro Menduran   \n",
              "...       ...       ...            ...                                ...   \n",
              "9916      300       425              2        Waterpark Kenjeran Surabaya   \n",
              "9917      300        64              4     Museum Sasmita Loka Ahmad Yani   \n",
              "9918      300       311              3                 The Lodge Maribaya   \n",
              "9919      300       279              4  Masjid Agung Trans Studio Bandung   \n",
              "9920      300       163              2                Watu Mabur Mangunan   \n",
              "\n",
              "                                            Description       Category  \\\n",
              "0     Situs Ratu Baka atau Candi Boko (Hanacaraka:ꦕꦤ...         Budaya   \n",
              "1     Pantai Marina (bahasa Jawa: ꦥꦱꦶꦱꦶꦂ​ꦩꦫꦶꦤ, trans...         Bahari   \n",
              "2     Atlantis Water Adventure atau dikenal dengan A...  Taman Hiburan   \n",
              "3     Museum Kereta Api Ambarawa (bahasa Inggris: In...         Budaya   \n",
              "4     Kampung wisata Sosromenduran merupakan kampung...         Budaya   \n",
              "...                                                 ...            ...   \n",
              "9916  Waterpark Kenjeran Surabaya merupakan wisata k...  Taman Hiburan   \n",
              "9917  Museum Sasmita Loka Ahmad Yani adalah salah sa...         Budaya   \n",
              "9918  The Lodge Maribaya adalah salah satu tempat wi...     Cagar Alam   \n",
              "9919  Masjid Agung Trans Studio Bandung (TSB) berdir...  Tempat Ibadah   \n",
              "9920  Kawasan Tebing Watu Mabur ini terbilang belum ...     Cagar Alam   \n",
              "\n",
              "            City  Price  \n",
              "0     Yogyakarta  75000  \n",
              "1       Semarang   3000  \n",
              "2        Jakarta  94000  \n",
              "3       Semarang  10000  \n",
              "4     Yogyakarta      0  \n",
              "...          ...    ...  \n",
              "9916    Surabaya  35000  \n",
              "9917     Jakarta   2000  \n",
              "9918     Bandung  25000  \n",
              "9919     Bandung      0  \n",
              "9920  Yogyakarta   2500  \n",
              "\n",
              "[9921 rows x 8 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_merged = rates.merge(places, on='Place_Id')\n",
        "df_merged"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdzPdre3LvYe",
        "outputId": "64e2e342-fe82-4c36-827c-0f009ab95147"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9921 entries, 0 to 9920\n",
            "Data columns (total 8 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   User_Id        9921 non-null   int64 \n",
            " 1   Place_Id       9921 non-null   int64 \n",
            " 2   Place_Ratings  9921 non-null   int64 \n",
            " 3   Place_Name     9921 non-null   object\n",
            " 4   Description    9921 non-null   object\n",
            " 5   Category       9921 non-null   object\n",
            " 6   City           9921 non-null   object\n",
            " 7   Price          9921 non-null   int64 \n",
            "dtypes: int64(4), object(4)\n",
            "memory usage: 620.2+ KB\n"
          ]
        }
      ],
      "source": [
        "df_merged.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hz-eZW8OsrTa"
      },
      "source": [
        "## Pre-processing\n",
        "\n",
        "encode users and places as integer indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjKH413osx58",
        "outputId": "f831653d-c3a0-404e-d6c2-6359864a0b85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of users: 300, Number of Places: 437, Min rating: 1, Max rating: 5\n"
          ]
        }
      ],
      "source": [
        "user_ids = df_merged[\"User_Id\"].unique().tolist()\n",
        "user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
        "userencoded2user = {i: x for i, x in enumerate(user_ids)}\n",
        "\n",
        "place_ids = df_merged[\"Place_Id\"].unique().tolist()\n",
        "place2place_encoded = {x: i for i, x in enumerate(place_ids)}\n",
        "place_encoded2place = {i: x for i, x in enumerate(place_ids)}\n",
        "\n",
        "df_merged[\"user\"] = df_merged[\"User_Id\"].map(user2user_encoded)\n",
        "df_merged[\"place\"] = df_merged[\"Place_Id\"].map(place2place_encoded)\n",
        "\n",
        "num_users = len(user2user_encoded)\n",
        "num_places = len(place_encoded2place)\n",
        "df_merged[\"rating\"] = df_merged[\"Place_Ratings\"].values.astype(np.float32)\n",
        "# min and max ratings will be used to normalize the ratings later\n",
        "\n",
        "min_rating = min(df_merged[\"Place_Ratings\"])\n",
        "max_rating = max(df_merged[\"Place_Ratings\"])\n",
        "\n",
        "print(\n",
        "    \"Number of users: {}, Number of Places: {}, Min rating: {}, Max rating: {}\".format(\n",
        "        num_users, num_places, min_rating, max_rating\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_FOrSsRtAQr"
      },
      "source": [
        "## Prepare traning and validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "e8duC5j8tCih"
      },
      "outputs": [],
      "source": [
        "df = df_merged.sample(frac=1, random_state=42)\n",
        "x = df[[\"user\", \"place\"]].values\n",
        "# Normalize the targets between 0 and 1. Makes it easy to train.\n",
        "y = df[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values\n",
        "# Assuming training on 90% of the data and validating on 10%.\n",
        "# In this destinatik, assuming 90%\n",
        "train_indices = int(0.9 * df.shape[0])\n",
        "x_train, x_val, y_train, y_val = (\n",
        "    x[:train_indices],\n",
        "    x[train_indices:],\n",
        "    y[:train_indices],\n",
        "    y[train_indices:],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TklG5tz8Mp9Z"
      },
      "source": [
        "## Create the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "NTMs-IiVt4eY"
      },
      "outputs": [],
      "source": [
        "from keras.utils import register_keras_serializable\n",
        "\n",
        "EMBEDDING_SIZE = 100\n",
        "\n",
        "@register_keras_serializable()\n",
        "class RecommenderNet(keras.Model):\n",
        "    def __init__(self, num_users, num_places, embedding_size, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.num_users = num_users\n",
        "        self.num_places = num_places\n",
        "        self.embedding_size = embedding_size\n",
        "        self.user_embedding = layers.Embedding(\n",
        "            num_users,\n",
        "            embedding_size,\n",
        "            embeddings_initializer=\"he_normal\",\n",
        "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
        "        )\n",
        "        self.user_bias = layers.Embedding(num_users, 1)\n",
        "        self.place_embedding = layers.Embedding(\n",
        "            num_places,\n",
        "            embedding_size,\n",
        "            embeddings_initializer=\"he_normal\",\n",
        "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
        "        )\n",
        "        self.place_bias = layers.Embedding(num_places, 1)\n",
        "        self.dropout = layers.Dropout(0.5)  # Add dropout layer\n",
        "\n",
        "    def call(self, inputs):\n",
        "        user_vector = self.user_embedding(inputs[:, 0])\n",
        "        user_bias = self.user_bias(inputs[:, 0])\n",
        "        place_vector = self.place_embedding(inputs[:, 1])\n",
        "        place_bias = self.place_bias(inputs[:, 1])\n",
        "        dot_user_place = ops.tensordot(user_vector, place_vector, 2)\n",
        "        # Add all the components (including bias)\n",
        "        x = dot_user_place + user_bias + place_bias\n",
        "        # The sigmoid activation forces the rating to between 0 and 1\n",
        "        x = self.dropout(x)  # Apply dropout\n",
        "        return ops.nn.sigmoid(x)\n",
        "    \n",
        "    # @classmethod\n",
        "    # def from_config(cls, config):\n",
        "    #     return cls(**config)\n",
        "    \n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(num_users=config['num_users'], num_places=config['num_places'], embedding_size=config['embedding_size'])\n",
        "\n",
        "\n",
        "model = RecommenderNet(num_users, num_places, EMBEDDING_SIZE)\n",
        "model.compile(\n",
        "    # loss=keras.losses.BinaryCrossentropy(),\n",
        "    loss=keras.losses.MeanSquaredError(),\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    metrics=[\n",
        "                keras.metrics.Accuracy(),\n",
        "            ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FU9djiYaM85q"
      },
      "source": [
        "## Train the model based on the data split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPTA4wHE5mEV",
        "outputId": "8ae565aa-d868-47ed-8270-7304745617c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.1299 - val_accuracy: 0.0000e+00 - val_loss: 0.1329\n",
            "Epoch 2/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: 0.1312 - val_accuracy: 0.0000e+00 - val_loss: 0.1327\n",
            "Epoch 3/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.1305 - val_accuracy: 0.0000e+00 - val_loss: 0.1325\n",
            "Epoch 4/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 0.1269 - val_accuracy: 0.0000e+00 - val_loss: 0.1322\n",
            "Epoch 5/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1322 - val_accuracy: 0.0000e+00 - val_loss: 0.1319\n",
            "Epoch 6/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: 0.1308 - val_accuracy: 0.0000e+00 - val_loss: 0.1317\n",
            "Epoch 7/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1280 - val_accuracy: 0.0000e+00 - val_loss: 0.1313\n",
            "Epoch 8/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: 0.1324 - val_accuracy: 0.0000e+00 - val_loss: 0.1310\n",
            "Epoch 9/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1249 - val_accuracy: 0.0000e+00 - val_loss: 0.1307\n",
            "Epoch 10/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.1233 - val_accuracy: 0.0000e+00 - val_loss: 0.1309\n",
            "Epoch 11/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1277 - val_accuracy: 0.0000e+00 - val_loss: 0.1311\n",
            "Epoch 12/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1270 - val_accuracy: 0.0000e+00 - val_loss: 0.1309\n",
            "Epoch 13/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1272 - val_accuracy: 0.0000e+00 - val_loss: 0.1311\n",
            "Epoch 14/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1270 - val_accuracy: 0.0000e+00 - val_loss: 0.1308\n",
            "Epoch 15/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1301 - val_accuracy: 0.0000e+00 - val_loss: 0.1307\n",
            "Epoch 16/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1275 - val_accuracy: 0.0000e+00 - val_loss: 0.1306\n",
            "Epoch 17/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1271 - val_accuracy: 0.0000e+00 - val_loss: 0.1304\n",
            "Epoch 18/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1213 - val_accuracy: 0.0000e+00 - val_loss: 0.1304\n",
            "Epoch 19/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1277 - val_accuracy: 0.0000e+00 - val_loss: 0.1303\n",
            "Epoch 20/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1274 - val_accuracy: 0.0000e+00 - val_loss: 0.1301\n",
            "Epoch 21/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1249 - val_accuracy: 0.0000e+00 - val_loss: 0.1301\n",
            "Epoch 22/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1250 - val_accuracy: 0.0000e+00 - val_loss: 0.1299\n",
            "Epoch 23/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.1248 - val_accuracy: 0.0000e+00 - val_loss: 0.1297\n",
            "Epoch 24/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: 0.1227 - val_accuracy: 0.0000e+00 - val_loss: 0.1297\n",
            "Epoch 25/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: 0.1223 - val_accuracy: 0.0000e+00 - val_loss: 0.1295\n",
            "Epoch 26/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: 0.1275 - val_accuracy: 0.0000e+00 - val_loss: 0.1296\n",
            "Epoch 27/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1294 - val_accuracy: 0.0000e+00 - val_loss: 0.1295\n",
            "Epoch 28/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1253 - val_accuracy: 0.0000e+00 - val_loss: 0.1295\n",
            "Epoch 29/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1249 - val_accuracy: 0.0000e+00 - val_loss: 0.1293\n",
            "Epoch 30/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: 0.1288 - val_accuracy: 0.0000e+00 - val_loss: 0.1293\n",
            "Epoch 31/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1230 - val_accuracy: 0.0000e+00 - val_loss: 0.1292\n",
            "Epoch 32/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1242 - val_accuracy: 0.0000e+00 - val_loss: 0.1291\n",
            "Epoch 33/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1215 - val_accuracy: 0.0000e+00 - val_loss: 0.1292\n",
            "Epoch 34/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1230 - val_accuracy: 0.0000e+00 - val_loss: 0.1291\n",
            "Epoch 35/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1228 - val_accuracy: 0.0000e+00 - val_loss: 0.1290\n",
            "Epoch 36/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1225 - val_accuracy: 0.0000e+00 - val_loss: 0.1288\n",
            "Epoch 37/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: 0.1234 - val_accuracy: 0.0000e+00 - val_loss: 0.1286\n",
            "Epoch 38/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1225 - val_accuracy: 0.0000e+00 - val_loss: 0.1288\n",
            "Epoch 39/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1217 - val_accuracy: 0.0000e+00 - val_loss: 0.1287\n",
            "Epoch 40/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: 0.1193 - val_accuracy: 0.0000e+00 - val_loss: 0.1285\n",
            "Epoch 41/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1211 - val_accuracy: 0.0000e+00 - val_loss: 0.1286\n",
            "Epoch 42/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: 0.1200 - val_accuracy: 0.0000e+00 - val_loss: 0.1286\n",
            "Epoch 43/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1201 - val_accuracy: 0.0000e+00 - val_loss: 0.1287\n",
            "Epoch 44/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: 0.1217 - val_accuracy: 0.0000e+00 - val_loss: 0.1286\n",
            "Epoch 45/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1213 - val_accuracy: 0.0000e+00 - val_loss: 0.1289\n",
            "Epoch 46/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1193 - val_accuracy: 0.0000e+00 - val_loss: 0.1289\n",
            "Epoch 47/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1208 - val_accuracy: 0.0000e+00 - val_loss: 0.1290\n",
            "Epoch 48/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1221 - val_accuracy: 0.0000e+00 - val_loss: 0.1291\n",
            "Epoch 49/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1189 - val_accuracy: 0.0000e+00 - val_loss: 0.1291\n",
            "Epoch 50/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1194 - val_accuracy: 0.0000e+00 - val_loss: 0.1290\n",
            "Epoch 51/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1200 - val_accuracy: 0.0000e+00 - val_loss: 0.1289\n",
            "Epoch 52/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1183 - val_accuracy: 0.0000e+00 - val_loss: 0.1289\n",
            "Epoch 53/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1185 - val_accuracy: 0.0000e+00 - val_loss: 0.1288\n",
            "Epoch 54/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1191 - val_accuracy: 0.0000e+00 - val_loss: 0.1290\n",
            "Epoch 55/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1229 - val_accuracy: 0.0000e+00 - val_loss: 0.1289\n",
            "Epoch 56/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1171 - val_accuracy: 0.0000e+00 - val_loss: 0.1289\n",
            "Epoch 57/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1191 - val_accuracy: 0.0000e+00 - val_loss: 0.1289\n",
            "Epoch 58/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1171 - val_accuracy: 0.0000e+00 - val_loss: 0.1289\n",
            "Epoch 59/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1166 - val_accuracy: 0.0000e+00 - val_loss: 0.1288\n",
            "Epoch 60/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1188 - val_accuracy: 0.0000e+00 - val_loss: 0.1290\n",
            "Epoch 61/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1187 - val_accuracy: 0.0000e+00 - val_loss: 0.1289\n",
            "Epoch 62/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1176 - val_accuracy: 0.0000e+00 - val_loss: 0.1289\n",
            "Epoch 63/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1189 - val_accuracy: 0.0000e+00 - val_loss: 0.1290\n",
            "Epoch 64/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1188 - val_accuracy: 0.0000e+00 - val_loss: 0.1289\n",
            "Epoch 65/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1177 - val_accuracy: 0.0000e+00 - val_loss: 0.1288\n",
            "Epoch 66/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1179 - val_accuracy: 0.0000e+00 - val_loss: 0.1286\n",
            "Epoch 67/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1202 - val_accuracy: 0.0000e+00 - val_loss: 0.1285\n",
            "Epoch 68/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1181 - val_accuracy: 0.0000e+00 - val_loss: 0.1283\n",
            "Epoch 69/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1159 - val_accuracy: 0.0000e+00 - val_loss: 0.1283\n",
            "Epoch 70/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1175 - val_accuracy: 0.0000e+00 - val_loss: 0.1283\n",
            "Epoch 71/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1165 - val_accuracy: 0.0000e+00 - val_loss: 0.1284\n",
            "Epoch 72/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1202 - val_accuracy: 0.0000e+00 - val_loss: 0.1287\n",
            "Epoch 73/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1169 - val_accuracy: 0.0000e+00 - val_loss: 0.1286\n",
            "Epoch 74/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1180 - val_accuracy: 0.0000e+00 - val_loss: 0.1287\n",
            "Epoch 75/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1170 - val_accuracy: 0.0000e+00 - val_loss: 0.1287\n",
            "Epoch 76/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1173 - val_accuracy: 0.0000e+00 - val_loss: 0.1287\n",
            "Epoch 77/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1166 - val_accuracy: 0.0000e+00 - val_loss: 0.1287\n",
            "Epoch 78/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1183 - val_accuracy: 0.0000e+00 - val_loss: 0.1288\n",
            "Epoch 79/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1167 - val_accuracy: 0.0000e+00 - val_loss: 0.1288\n",
            "Epoch 80/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1148 - val_accuracy: 0.0000e+00 - val_loss: 0.1289\n",
            "Epoch 81/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1171 - val_accuracy: 0.0000e+00 - val_loss: 0.1290\n",
            "Epoch 82/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1157 - val_accuracy: 0.0000e+00 - val_loss: 0.1288\n",
            "Epoch 83/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1149 - val_accuracy: 0.0000e+00 - val_loss: 0.1290\n",
            "Epoch 84/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1150 - val_accuracy: 0.0000e+00 - val_loss: 0.1290\n",
            "Epoch 85/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1144 - val_accuracy: 0.0000e+00 - val_loss: 0.1290\n",
            "Epoch 86/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1144 - val_accuracy: 0.0000e+00 - val_loss: 0.1289\n",
            "Epoch 87/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1132 - val_accuracy: 0.0000e+00 - val_loss: 0.1289\n",
            "Epoch 88/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1160 - val_accuracy: 0.0000e+00 - val_loss: 0.1288\n",
            "Epoch 89/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1149 - val_accuracy: 0.0000e+00 - val_loss: 0.1288\n",
            "Epoch 90/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1144 - val_accuracy: 0.0000e+00 - val_loss: 0.1287\n",
            "Epoch 91/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1161 - val_accuracy: 0.0000e+00 - val_loss: 0.1287\n",
            "Epoch 92/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1144 - val_accuracy: 0.0000e+00 - val_loss: 0.1287\n",
            "Epoch 93/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1150 - val_accuracy: 0.0000e+00 - val_loss: 0.1287\n",
            "Epoch 94/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1139 - val_accuracy: 0.0000e+00 - val_loss: 0.1288\n",
            "Epoch 95/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1167 - val_accuracy: 0.0000e+00 - val_loss: 0.1288\n",
            "Epoch 96/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1133 - val_accuracy: 0.0000e+00 - val_loss: 0.1287\n",
            "Epoch 97/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1139 - val_accuracy: 0.0000e+00 - val_loss: 0.1284\n",
            "Epoch 98/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1149 - val_accuracy: 0.0000e+00 - val_loss: 0.1284\n",
            "Epoch 99/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1149 - val_accuracy: 0.0000e+00 - val_loss: 0.1284\n",
            "Epoch 100/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1120 - val_accuracy: 0.0000e+00 - val_loss: 0.1283\n",
            "Epoch 101/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1130 - val_accuracy: 0.0000e+00 - val_loss: 0.1282\n",
            "Epoch 102/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1123 - val_accuracy: 0.0000e+00 - val_loss: 0.1282\n",
            "Epoch 103/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1130 - val_accuracy: 0.0000e+00 - val_loss: 0.1282\n",
            "Epoch 104/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1133 - val_accuracy: 0.0000e+00 - val_loss: 0.1280\n",
            "Epoch 105/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1154 - val_accuracy: 0.0000e+00 - val_loss: 0.1279\n",
            "Epoch 106/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1136 - val_accuracy: 0.0000e+00 - val_loss: 0.1277\n",
            "Epoch 107/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1146 - val_accuracy: 0.0000e+00 - val_loss: 0.1276\n",
            "Epoch 108/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1151 - val_accuracy: 0.0000e+00 - val_loss: 0.1276\n",
            "Epoch 109/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1120 - val_accuracy: 0.0000e+00 - val_loss: 0.1276\n",
            "Epoch 110/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1142 - val_accuracy: 0.0000e+00 - val_loss: 0.1278\n",
            "Epoch 111/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1127 - val_accuracy: 0.0000e+00 - val_loss: 0.1279\n",
            "Epoch 112/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1130 - val_accuracy: 0.0000e+00 - val_loss: 0.1278\n",
            "Epoch 113/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1153 - val_accuracy: 0.0000e+00 - val_loss: 0.1279\n",
            "Epoch 114/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1142 - val_accuracy: 0.0000e+00 - val_loss: 0.1279\n",
            "Epoch 115/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1126 - val_accuracy: 0.0000e+00 - val_loss: 0.1278\n",
            "Epoch 116/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1142 - val_accuracy: 0.0000e+00 - val_loss: 0.1281\n",
            "Epoch 117/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1122 - val_accuracy: 0.0000e+00 - val_loss: 0.1281\n",
            "Epoch 118/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1127 - val_accuracy: 0.0000e+00 - val_loss: 0.1281\n",
            "Epoch 119/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1131 - val_accuracy: 0.0000e+00 - val_loss: 0.1281\n",
            "Epoch 120/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1126 - val_accuracy: 0.0000e+00 - val_loss: 0.1281\n",
            "Epoch 121/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1132 - val_accuracy: 0.0000e+00 - val_loss: 0.1282\n",
            "Epoch 122/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1109 - val_accuracy: 0.0000e+00 - val_loss: 0.1283\n",
            "Epoch 123/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1122 - val_accuracy: 0.0000e+00 - val_loss: 0.1282\n",
            "Epoch 124/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1126 - val_accuracy: 0.0000e+00 - val_loss: 0.1282\n",
            "Epoch 125/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1135 - val_accuracy: 0.0000e+00 - val_loss: 0.1282\n",
            "Epoch 126/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1138 - val_accuracy: 0.0000e+00 - val_loss: 0.1282\n",
            "Epoch 127/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1127 - val_accuracy: 0.0000e+00 - val_loss: 0.1281\n",
            "Epoch 128/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1121 - val_accuracy: 0.0000e+00 - val_loss: 0.1281\n",
            "Epoch 129/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1137 - val_accuracy: 0.0000e+00 - val_loss: 0.1280\n",
            "Epoch 130/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1127 - val_accuracy: 0.0000e+00 - val_loss: 0.1280\n",
            "Epoch 131/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1121 - val_accuracy: 0.0000e+00 - val_loss: 0.1280\n",
            "Epoch 132/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1112 - val_accuracy: 0.0000e+00 - val_loss: 0.1280\n",
            "Epoch 133/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1119 - val_accuracy: 0.0000e+00 - val_loss: 0.1280\n",
            "Epoch 134/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1118 - val_accuracy: 0.0000e+00 - val_loss: 0.1280\n",
            "Epoch 135/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1106 - val_accuracy: 0.0000e+00 - val_loss: 0.1281\n",
            "Epoch 136/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1123 - val_accuracy: 0.0000e+00 - val_loss: 0.1282\n",
            "Epoch 137/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1120 - val_accuracy: 0.0000e+00 - val_loss: 0.1281\n",
            "Epoch 138/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1110 - val_accuracy: 0.0000e+00 - val_loss: 0.1281\n",
            "Epoch 139/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1123 - val_accuracy: 0.0000e+00 - val_loss: 0.1280\n",
            "Epoch 140/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1098 - val_accuracy: 0.0000e+00 - val_loss: 0.1281\n",
            "Epoch 141/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1106 - val_accuracy: 0.0000e+00 - val_loss: 0.1280\n",
            "Epoch 142/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1100 - val_accuracy: 0.0000e+00 - val_loss: 0.1281\n",
            "Epoch 143/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1118 - val_accuracy: 0.0000e+00 - val_loss: 0.1281\n",
            "Epoch 144/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1106 - val_accuracy: 0.0000e+00 - val_loss: 0.1282\n",
            "Epoch 145/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1114 - val_accuracy: 0.0000e+00 - val_loss: 0.1284\n",
            "Epoch 146/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1116 - val_accuracy: 0.0000e+00 - val_loss: 0.1283\n",
            "Epoch 147/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1118 - val_accuracy: 0.0000e+00 - val_loss: 0.1283\n",
            "Epoch 148/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1124 - val_accuracy: 0.0000e+00 - val_loss: 0.1284\n",
            "Epoch 149/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1092 - val_accuracy: 0.0000e+00 - val_loss: 0.1285\n",
            "Epoch 150/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1118 - val_accuracy: 0.0000e+00 - val_loss: 0.1285\n",
            "Epoch 151/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1084 - val_accuracy: 0.0000e+00 - val_loss: 0.1284\n",
            "Epoch 152/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1107 - val_accuracy: 0.0000e+00 - val_loss: 0.1285\n",
            "Epoch 153/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1102 - val_accuracy: 0.0000e+00 - val_loss: 0.1286\n",
            "Epoch 154/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1111 - val_accuracy: 0.0000e+00 - val_loss: 0.1288\n",
            "Epoch 155/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1093 - val_accuracy: 0.0000e+00 - val_loss: 0.1289\n",
            "Epoch 156/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1115 - val_accuracy: 0.0000e+00 - val_loss: 0.1289\n",
            "Epoch 157/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1106 - val_accuracy: 0.0000e+00 - val_loss: 0.1291\n",
            "Epoch 158/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1084 - val_accuracy: 0.0000e+00 - val_loss: 0.1292\n",
            "Epoch 159/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1118 - val_accuracy: 0.0000e+00 - val_loss: 0.1292\n",
            "Epoch 160/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1103 - val_accuracy: 0.0000e+00 - val_loss: 0.1291\n",
            "Epoch 161/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1104 - val_accuracy: 0.0000e+00 - val_loss: 0.1289\n",
            "Epoch 162/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1106 - val_accuracy: 0.0000e+00 - val_loss: 0.1290\n",
            "Epoch 163/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1120 - val_accuracy: 0.0000e+00 - val_loss: 0.1289\n",
            "Epoch 164/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1104 - val_accuracy: 0.0000e+00 - val_loss: 0.1288\n",
            "Epoch 165/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1101 - val_accuracy: 0.0000e+00 - val_loss: 0.1289\n",
            "Epoch 166/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1122 - val_accuracy: 0.0000e+00 - val_loss: 0.1290\n",
            "Epoch 167/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1109 - val_accuracy: 0.0000e+00 - val_loss: 0.1290\n",
            "Epoch 168/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1101 - val_accuracy: 0.0000e+00 - val_loss: 0.1289\n",
            "Epoch 169/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1099 - val_accuracy: 0.0000e+00 - val_loss: 0.1288\n",
            "Epoch 170/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1122 - val_accuracy: 0.0000e+00 - val_loss: 0.1290\n",
            "Epoch 171/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1108 - val_accuracy: 0.0000e+00 - val_loss: 0.1289\n",
            "Epoch 172/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1092 - val_accuracy: 0.0000e+00 - val_loss: 0.1289\n",
            "Epoch 173/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1102 - val_accuracy: 0.0000e+00 - val_loss: 0.1290\n",
            "Epoch 174/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1100 - val_accuracy: 0.0000e+00 - val_loss: 0.1289\n",
            "Epoch 175/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1089 - val_accuracy: 0.0000e+00 - val_loss: 0.1289\n",
            "Epoch 176/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1106 - val_accuracy: 0.0000e+00 - val_loss: 0.1288\n",
            "Epoch 177/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1113 - val_accuracy: 0.0000e+00 - val_loss: 0.1287\n",
            "Epoch 178/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1112 - val_accuracy: 0.0000e+00 - val_loss: 0.1287\n",
            "Epoch 179/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1104 - val_accuracy: 0.0000e+00 - val_loss: 0.1287\n",
            "Epoch 180/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1088 - val_accuracy: 0.0000e+00 - val_loss: 0.1288\n",
            "Epoch 181/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1090 - val_accuracy: 0.0000e+00 - val_loss: 0.1287\n",
            "Epoch 182/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1092 - val_accuracy: 0.0000e+00 - val_loss: 0.1287\n",
            "Epoch 183/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1096 - val_accuracy: 0.0000e+00 - val_loss: 0.1287\n",
            "Epoch 184/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1103 - val_accuracy: 0.0000e+00 - val_loss: 0.1288\n",
            "Epoch 185/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1103 - val_accuracy: 0.0000e+00 - val_loss: 0.1290\n",
            "Epoch 186/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1105 - val_accuracy: 0.0000e+00 - val_loss: 0.1290\n",
            "Epoch 187/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1099 - val_accuracy: 0.0000e+00 - val_loss: 0.1291\n",
            "Epoch 188/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1088 - val_accuracy: 0.0000e+00 - val_loss: 0.1292\n",
            "Epoch 189/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1112 - val_accuracy: 0.0000e+00 - val_loss: 0.1293\n",
            "Epoch 190/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1079 - val_accuracy: 0.0000e+00 - val_loss: 0.1292\n",
            "Epoch 191/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1106 - val_accuracy: 0.0000e+00 - val_loss: 0.1291\n",
            "Epoch 192/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1069 - val_accuracy: 0.0000e+00 - val_loss: 0.1293\n",
            "Epoch 193/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1092 - val_accuracy: 0.0000e+00 - val_loss: 0.1292\n",
            "Epoch 194/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1078 - val_accuracy: 0.0000e+00 - val_loss: 0.1293\n",
            "Epoch 195/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1093 - val_accuracy: 0.0000e+00 - val_loss: 0.1294\n",
            "Epoch 196/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1115 - val_accuracy: 0.0000e+00 - val_loss: 0.1293\n",
            "Epoch 197/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1089 - val_accuracy: 0.0000e+00 - val_loss: 0.1293\n",
            "Epoch 198/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1097 - val_accuracy: 0.0000e+00 - val_loss: 0.1293\n",
            "Epoch 199/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1096 - val_accuracy: 0.0000e+00 - val_loss: 0.1293\n",
            "Epoch 200/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1100 - val_accuracy: 0.0000e+00 - val_loss: 0.1294\n",
            "Epoch 201/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1118 - val_accuracy: 0.0000e+00 - val_loss: 0.1295\n",
            "Epoch 202/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1098 - val_accuracy: 0.0000e+00 - val_loss: 0.1295\n",
            "Epoch 203/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1087 - val_accuracy: 0.0000e+00 - val_loss: 0.1295\n",
            "Epoch 204/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1088 - val_accuracy: 0.0000e+00 - val_loss: 0.1295\n",
            "Epoch 205/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1078 - val_accuracy: 0.0000e+00 - val_loss: 0.1295\n",
            "Epoch 206/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1078 - val_accuracy: 0.0000e+00 - val_loss: 0.1296\n",
            "Epoch 207/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1081 - val_accuracy: 0.0000e+00 - val_loss: 0.1296\n",
            "Epoch 208/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1086 - val_accuracy: 0.0000e+00 - val_loss: 0.1296\n",
            "Epoch 209/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1090 - val_accuracy: 0.0000e+00 - val_loss: 0.1298\n",
            "Epoch 210/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1086 - val_accuracy: 0.0000e+00 - val_loss: 0.1297\n",
            "Epoch 211/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1085 - val_accuracy: 0.0000e+00 - val_loss: 0.1296\n",
            "Epoch 212/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1080 - val_accuracy: 0.0000e+00 - val_loss: 0.1297\n",
            "Epoch 213/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1085 - val_accuracy: 0.0000e+00 - val_loss: 0.1299\n",
            "Epoch 214/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1085 - val_accuracy: 0.0000e+00 - val_loss: 0.1299\n",
            "Epoch 215/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1085 - val_accuracy: 0.0000e+00 - val_loss: 0.1297\n",
            "Epoch 216/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1098 - val_accuracy: 0.0000e+00 - val_loss: 0.1297\n",
            "Epoch 217/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1083 - val_accuracy: 0.0000e+00 - val_loss: 0.1300\n",
            "Epoch 218/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1098 - val_accuracy: 0.0000e+00 - val_loss: 0.1300\n",
            "Epoch 219/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1090 - val_accuracy: 0.0000e+00 - val_loss: 0.1300\n",
            "Epoch 220/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1093 - val_accuracy: 0.0000e+00 - val_loss: 0.1300\n",
            "Epoch 221/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1096 - val_accuracy: 0.0000e+00 - val_loss: 0.1297\n",
            "Epoch 222/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1091 - val_accuracy: 0.0000e+00 - val_loss: 0.1297\n",
            "Epoch 223/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1089 - val_accuracy: 0.0000e+00 - val_loss: 0.1297\n",
            "Epoch 224/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1066 - val_accuracy: 0.0000e+00 - val_loss: 0.1297\n",
            "Epoch 225/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1094 - val_accuracy: 0.0000e+00 - val_loss: 0.1298\n",
            "Epoch 226/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1072 - val_accuracy: 0.0000e+00 - val_loss: 0.1297\n",
            "Epoch 227/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1078 - val_accuracy: 0.0000e+00 - val_loss: 0.1296\n",
            "Epoch 228/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1083 - val_accuracy: 0.0000e+00 - val_loss: 0.1296\n",
            "Epoch 229/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1086 - val_accuracy: 0.0000e+00 - val_loss: 0.1296\n",
            "Epoch 230/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1073 - val_accuracy: 0.0000e+00 - val_loss: 0.1295\n",
            "Epoch 231/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1095 - val_accuracy: 0.0000e+00 - val_loss: 0.1295\n",
            "Epoch 232/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1084 - val_accuracy: 0.0000e+00 - val_loss: 0.1295\n",
            "Epoch 233/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1098 - val_accuracy: 0.0000e+00 - val_loss: 0.1295\n",
            "Epoch 234/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1081 - val_accuracy: 0.0000e+00 - val_loss: 0.1296\n",
            "Epoch 235/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1077 - val_accuracy: 0.0000e+00 - val_loss: 0.1296\n",
            "Epoch 236/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1073 - val_accuracy: 0.0000e+00 - val_loss: 0.1297\n",
            "Epoch 237/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1094 - val_accuracy: 0.0000e+00 - val_loss: 0.1299\n",
            "Epoch 238/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1079 - val_accuracy: 0.0000e+00 - val_loss: 0.1299\n",
            "Epoch 239/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1071 - val_accuracy: 0.0000e+00 - val_loss: 0.1300\n",
            "Epoch 240/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1102 - val_accuracy: 0.0000e+00 - val_loss: 0.1301\n",
            "Epoch 241/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1076 - val_accuracy: 0.0000e+00 - val_loss: 0.1301\n",
            "Epoch 242/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1091 - val_accuracy: 0.0000e+00 - val_loss: 0.1300\n",
            "Epoch 243/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1084 - val_accuracy: 0.0000e+00 - val_loss: 0.1300\n",
            "Epoch 244/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1093 - val_accuracy: 0.0000e+00 - val_loss: 0.1300\n",
            "Epoch 245/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1084 - val_accuracy: 0.0000e+00 - val_loss: 0.1299\n",
            "Epoch 246/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1098 - val_accuracy: 0.0000e+00 - val_loss: 0.1299\n",
            "Epoch 247/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1070 - val_accuracy: 0.0000e+00 - val_loss: 0.1300\n",
            "Epoch 248/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1084 - val_accuracy: 0.0000e+00 - val_loss: 0.1300\n",
            "Epoch 249/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1098 - val_accuracy: 0.0000e+00 - val_loss: 0.1301\n",
            "Epoch 250/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1086 - val_accuracy: 0.0000e+00 - val_loss: 0.1301\n",
            "Epoch 251/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1080 - val_accuracy: 0.0000e+00 - val_loss: 0.1300\n",
            "Epoch 252/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1067 - val_accuracy: 0.0000e+00 - val_loss: 0.1301\n",
            "Epoch 253/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1080 - val_accuracy: 0.0000e+00 - val_loss: 0.1301\n",
            "Epoch 254/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1084 - val_accuracy: 0.0000e+00 - val_loss: 0.1302\n",
            "Epoch 255/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1091 - val_accuracy: 0.0000e+00 - val_loss: 0.1302\n",
            "Epoch 256/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1083 - val_accuracy: 0.0000e+00 - val_loss: 0.1301\n",
            "Epoch 257/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1070 - val_accuracy: 0.0000e+00 - val_loss: 0.1299\n",
            "Epoch 258/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1085 - val_accuracy: 0.0000e+00 - val_loss: 0.1299\n",
            "Epoch 259/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1088 - val_accuracy: 0.0000e+00 - val_loss: 0.1299\n",
            "Epoch 260/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1066 - val_accuracy: 0.0000e+00 - val_loss: 0.1300\n",
            "Epoch 261/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1078 - val_accuracy: 0.0000e+00 - val_loss: 0.1302\n",
            "Epoch 262/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1068 - val_accuracy: 0.0000e+00 - val_loss: 0.1301\n",
            "Epoch 263/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1094 - val_accuracy: 0.0000e+00 - val_loss: 0.1303\n",
            "Epoch 264/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1085 - val_accuracy: 0.0000e+00 - val_loss: 0.1303\n",
            "Epoch 265/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1083 - val_accuracy: 0.0000e+00 - val_loss: 0.1303\n",
            "Epoch 266/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1073 - val_accuracy: 0.0000e+00 - val_loss: 0.1302\n",
            "Epoch 267/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1095 - val_accuracy: 0.0000e+00 - val_loss: 0.1304\n",
            "Epoch 268/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1069 - val_accuracy: 0.0000e+00 - val_loss: 0.1305\n",
            "Epoch 269/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1083 - val_accuracy: 0.0000e+00 - val_loss: 0.1306\n",
            "Epoch 270/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1065 - val_accuracy: 0.0000e+00 - val_loss: 0.1304\n",
            "Epoch 271/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1081 - val_accuracy: 0.0000e+00 - val_loss: 0.1305\n",
            "Epoch 272/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1073 - val_accuracy: 0.0000e+00 - val_loss: 0.1305\n",
            "Epoch 273/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1071 - val_accuracy: 0.0000e+00 - val_loss: 0.1305\n",
            "Epoch 274/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1073 - val_accuracy: 0.0000e+00 - val_loss: 0.1308\n",
            "Epoch 275/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1080 - val_accuracy: 0.0000e+00 - val_loss: 0.1307\n",
            "Epoch 276/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1077 - val_accuracy: 0.0000e+00 - val_loss: 0.1307\n",
            "Epoch 277/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1075 - val_accuracy: 0.0000e+00 - val_loss: 0.1306\n",
            "Epoch 278/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1071 - val_accuracy: 0.0000e+00 - val_loss: 0.1306\n",
            "Epoch 279/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1080 - val_accuracy: 0.0000e+00 - val_loss: 0.1305\n",
            "Epoch 280/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1086 - val_accuracy: 0.0000e+00 - val_loss: 0.1305\n",
            "Epoch 281/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1090 - val_accuracy: 0.0000e+00 - val_loss: 0.1304\n",
            "Epoch 282/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1066 - val_accuracy: 0.0000e+00 - val_loss: 0.1304\n",
            "Epoch 283/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1091 - val_accuracy: 0.0000e+00 - val_loss: 0.1303\n",
            "Epoch 284/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1088 - val_accuracy: 0.0000e+00 - val_loss: 0.1304\n",
            "Epoch 285/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1086 - val_accuracy: 0.0000e+00 - val_loss: 0.1304\n",
            "Epoch 286/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1070 - val_accuracy: 0.0000e+00 - val_loss: 0.1304\n",
            "Epoch 287/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1073 - val_accuracy: 0.0000e+00 - val_loss: 0.1304\n",
            "Epoch 288/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1077 - val_accuracy: 0.0000e+00 - val_loss: 0.1304\n",
            "Epoch 289/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1055 - val_accuracy: 0.0000e+00 - val_loss: 0.1303\n",
            "Epoch 290/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1079 - val_accuracy: 0.0000e+00 - val_loss: 0.1303\n",
            "Epoch 291/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1083 - val_accuracy: 0.0000e+00 - val_loss: 0.1303\n",
            "Epoch 292/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1078 - val_accuracy: 0.0000e+00 - val_loss: 0.1305\n",
            "Epoch 293/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1077 - val_accuracy: 0.0000e+00 - val_loss: 0.1305\n",
            "Epoch 294/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1070 - val_accuracy: 0.0000e+00 - val_loss: 0.1305\n",
            "Epoch 295/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1076 - val_accuracy: 0.0000e+00 - val_loss: 0.1305\n",
            "Epoch 296/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1068 - val_accuracy: 0.0000e+00 - val_loss: 0.1304\n",
            "Epoch 297/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1083 - val_accuracy: 0.0000e+00 - val_loss: 0.1302\n",
            "Epoch 298/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1072 - val_accuracy: 0.0000e+00 - val_loss: 0.1302\n",
            "Epoch 299/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1079 - val_accuracy: 0.0000e+00 - val_loss: 0.1301\n",
            "Epoch 300/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1077 - val_accuracy: 0.0000e+00 - val_loss: 0.1302\n",
            "Epoch 301/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1072 - val_accuracy: 0.0000e+00 - val_loss: 0.1304\n",
            "Epoch 302/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1067 - val_accuracy: 0.0000e+00 - val_loss: 0.1303\n",
            "Epoch 303/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1055 - val_accuracy: 0.0000e+00 - val_loss: 0.1303\n",
            "Epoch 304/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1094 - val_accuracy: 0.0000e+00 - val_loss: 0.1304\n",
            "Epoch 305/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1090 - val_accuracy: 0.0000e+00 - val_loss: 0.1307\n",
            "Epoch 306/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1062 - val_accuracy: 0.0000e+00 - val_loss: 0.1307\n",
            "Epoch 307/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1062 - val_accuracy: 0.0000e+00 - val_loss: 0.1307\n",
            "Epoch 308/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1064 - val_accuracy: 0.0000e+00 - val_loss: 0.1307\n",
            "Epoch 309/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1073 - val_accuracy: 0.0000e+00 - val_loss: 0.1308\n",
            "Epoch 310/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1081 - val_accuracy: 0.0000e+00 - val_loss: 0.1307\n",
            "Epoch 311/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1070 - val_accuracy: 0.0000e+00 - val_loss: 0.1307\n",
            "Epoch 312/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1074 - val_accuracy: 0.0000e+00 - val_loss: 0.1309\n",
            "Epoch 313/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1074 - val_accuracy: 0.0000e+00 - val_loss: 0.1308\n",
            "Epoch 314/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1073 - val_accuracy: 0.0000e+00 - val_loss: 0.1308\n",
            "Epoch 315/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1086 - val_accuracy: 0.0000e+00 - val_loss: 0.1308\n",
            "Epoch 316/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1079 - val_accuracy: 0.0000e+00 - val_loss: 0.1308\n",
            "Epoch 317/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1081 - val_accuracy: 0.0000e+00 - val_loss: 0.1306\n",
            "Epoch 318/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1084 - val_accuracy: 0.0000e+00 - val_loss: 0.1306\n",
            "Epoch 319/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1074 - val_accuracy: 0.0000e+00 - val_loss: 0.1306\n",
            "Epoch 320/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1101 - val_accuracy: 0.0000e+00 - val_loss: 0.1307\n",
            "Epoch 321/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1070 - val_accuracy: 0.0000e+00 - val_loss: 0.1307\n",
            "Epoch 322/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1060 - val_accuracy: 0.0000e+00 - val_loss: 0.1308\n",
            "Epoch 323/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1062 - val_accuracy: 0.0000e+00 - val_loss: 0.1308\n",
            "Epoch 324/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1085 - val_accuracy: 0.0000e+00 - val_loss: 0.1309\n",
            "Epoch 325/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1091 - val_accuracy: 0.0000e+00 - val_loss: 0.1309\n",
            "Epoch 326/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1094 - val_accuracy: 0.0000e+00 - val_loss: 0.1309\n",
            "Epoch 327/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1071 - val_accuracy: 0.0000e+00 - val_loss: 0.1308\n",
            "Epoch 328/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1071 - val_accuracy: 0.0000e+00 - val_loss: 0.1307\n",
            "Epoch 329/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1086 - val_accuracy: 0.0000e+00 - val_loss: 0.1309\n",
            "Epoch 330/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1094 - val_accuracy: 0.0000e+00 - val_loss: 0.1308\n",
            "Epoch 331/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1087 - val_accuracy: 0.0000e+00 - val_loss: 0.1309\n",
            "Epoch 332/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1093 - val_accuracy: 0.0000e+00 - val_loss: 0.1312\n",
            "Epoch 333/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1088 - val_accuracy: 0.0000e+00 - val_loss: 0.1312\n",
            "Epoch 334/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1078 - val_accuracy: 0.0000e+00 - val_loss: 0.1311\n",
            "Epoch 335/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1069 - val_accuracy: 0.0000e+00 - val_loss: 0.1311\n",
            "Epoch 336/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1098 - val_accuracy: 0.0000e+00 - val_loss: 0.1311\n",
            "Epoch 337/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1069 - val_accuracy: 0.0000e+00 - val_loss: 0.1312\n",
            "Epoch 338/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1053 - val_accuracy: 0.0000e+00 - val_loss: 0.1312\n",
            "Epoch 339/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1100 - val_accuracy: 0.0000e+00 - val_loss: 0.1312\n",
            "Epoch 340/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1056 - val_accuracy: 0.0000e+00 - val_loss: 0.1312\n",
            "Epoch 341/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1083 - val_accuracy: 0.0000e+00 - val_loss: 0.1312\n",
            "Epoch 342/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1064 - val_accuracy: 0.0000e+00 - val_loss: 0.1313\n",
            "Epoch 343/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1095 - val_accuracy: 0.0000e+00 - val_loss: 0.1313\n",
            "Epoch 344/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1095 - val_accuracy: 0.0000e+00 - val_loss: 0.1313\n",
            "Epoch 345/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1060 - val_accuracy: 0.0000e+00 - val_loss: 0.1313\n",
            "Epoch 346/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1076 - val_accuracy: 0.0000e+00 - val_loss: 0.1314\n",
            "Epoch 347/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1072 - val_accuracy: 0.0000e+00 - val_loss: 0.1315\n",
            "Epoch 348/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1059 - val_accuracy: 0.0000e+00 - val_loss: 0.1314\n",
            "Epoch 349/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1091 - val_accuracy: 0.0000e+00 - val_loss: 0.1313\n",
            "Epoch 350/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1068 - val_accuracy: 0.0000e+00 - val_loss: 0.1312\n",
            "Epoch 351/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1065 - val_accuracy: 0.0000e+00 - val_loss: 0.1314\n",
            "Epoch 352/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1088 - val_accuracy: 0.0000e+00 - val_loss: 0.1314\n",
            "Epoch 353/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1083 - val_accuracy: 0.0000e+00 - val_loss: 0.1314\n",
            "Epoch 354/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1078 - val_accuracy: 0.0000e+00 - val_loss: 0.1314\n",
            "Epoch 355/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1071 - val_accuracy: 0.0000e+00 - val_loss: 0.1313\n",
            "Epoch 356/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1062 - val_accuracy: 0.0000e+00 - val_loss: 0.1312\n",
            "Epoch 357/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1079 - val_accuracy: 0.0000e+00 - val_loss: 0.1310\n",
            "Epoch 358/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1087 - val_accuracy: 0.0000e+00 - val_loss: 0.1311\n",
            "Epoch 359/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1081 - val_accuracy: 0.0000e+00 - val_loss: 0.1311\n",
            "Epoch 360/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1072 - val_accuracy: 0.0000e+00 - val_loss: 0.1311\n",
            "Epoch 361/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1071 - val_accuracy: 0.0000e+00 - val_loss: 0.1311\n",
            "Epoch 362/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1063 - val_accuracy: 0.0000e+00 - val_loss: 0.1312\n",
            "Epoch 363/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1069 - val_accuracy: 0.0000e+00 - val_loss: 0.1312\n",
            "Epoch 364/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1075 - val_accuracy: 0.0000e+00 - val_loss: 0.1313\n",
            "Epoch 365/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1077 - val_accuracy: 0.0000e+00 - val_loss: 0.1313\n",
            "Epoch 366/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1074 - val_accuracy: 0.0000e+00 - val_loss: 0.1314\n",
            "Epoch 367/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1071 - val_accuracy: 0.0000e+00 - val_loss: 0.1315\n",
            "Epoch 368/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1083 - val_accuracy: 0.0000e+00 - val_loss: 0.1314\n",
            "Epoch 369/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1065 - val_accuracy: 0.0000e+00 - val_loss: 0.1315\n",
            "Epoch 370/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1077 - val_accuracy: 0.0000e+00 - val_loss: 0.1315\n",
            "Epoch 371/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1065 - val_accuracy: 0.0000e+00 - val_loss: 0.1316\n",
            "Epoch 372/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1086 - val_accuracy: 0.0000e+00 - val_loss: 0.1315\n",
            "Epoch 373/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1080 - val_accuracy: 0.0000e+00 - val_loss: 0.1315\n",
            "Epoch 374/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1062 - val_accuracy: 0.0000e+00 - val_loss: 0.1315\n",
            "Epoch 375/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1083 - val_accuracy: 0.0000e+00 - val_loss: 0.1314\n",
            "Epoch 376/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1063 - val_accuracy: 0.0000e+00 - val_loss: 0.1313\n",
            "Epoch 377/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1092 - val_accuracy: 0.0000e+00 - val_loss: 0.1313\n",
            "Epoch 378/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1071 - val_accuracy: 0.0000e+00 - val_loss: 0.1314\n",
            "Epoch 379/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1066 - val_accuracy: 0.0000e+00 - val_loss: 0.1314\n",
            "Epoch 380/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1080 - val_accuracy: 0.0000e+00 - val_loss: 0.1314\n",
            "Epoch 381/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1078 - val_accuracy: 0.0000e+00 - val_loss: 0.1313\n",
            "Epoch 382/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1081 - val_accuracy: 0.0000e+00 - val_loss: 0.1313\n",
            "Epoch 383/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1085 - val_accuracy: 0.0000e+00 - val_loss: 0.1315\n",
            "Epoch 384/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1078 - val_accuracy: 0.0000e+00 - val_loss: 0.1315\n",
            "Epoch 385/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1094 - val_accuracy: 0.0000e+00 - val_loss: 0.1314\n",
            "Epoch 386/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1066 - val_accuracy: 0.0000e+00 - val_loss: 0.1314\n",
            "Epoch 387/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1063 - val_accuracy: 0.0000e+00 - val_loss: 0.1313\n",
            "Epoch 388/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1094 - val_accuracy: 0.0000e+00 - val_loss: 0.1312\n",
            "Epoch 389/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1057 - val_accuracy: 0.0000e+00 - val_loss: 0.1313\n",
            "Epoch 390/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1078 - val_accuracy: 0.0000e+00 - val_loss: 0.1312\n",
            "Epoch 391/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1070 - val_accuracy: 0.0000e+00 - val_loss: 0.1312\n",
            "Epoch 392/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1094 - val_accuracy: 0.0000e+00 - val_loss: 0.1312\n",
            "Epoch 393/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1075 - val_accuracy: 0.0000e+00 - val_loss: 0.1314\n",
            "Epoch 394/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1062 - val_accuracy: 0.0000e+00 - val_loss: 0.1314\n",
            "Epoch 395/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1065 - val_accuracy: 0.0000e+00 - val_loss: 0.1315\n",
            "Epoch 396/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1076 - val_accuracy: 0.0000e+00 - val_loss: 0.1315\n",
            "Epoch 397/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1064 - val_accuracy: 0.0000e+00 - val_loss: 0.1317\n",
            "Epoch 398/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1068 - val_accuracy: 0.0000e+00 - val_loss: 0.1317\n",
            "Epoch 399/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1073 - val_accuracy: 0.0000e+00 - val_loss: 0.1316\n",
            "Epoch 400/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1090 - val_accuracy: 0.0000e+00 - val_loss: 0.1317\n",
            "Epoch 401/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1073 - val_accuracy: 0.0000e+00 - val_loss: 0.1318\n",
            "Epoch 402/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1071 - val_accuracy: 0.0000e+00 - val_loss: 0.1317\n",
            "Epoch 403/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1080 - val_accuracy: 0.0000e+00 - val_loss: 0.1316\n",
            "Epoch 404/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1055 - val_accuracy: 0.0000e+00 - val_loss: 0.1316\n",
            "Epoch 405/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1079 - val_accuracy: 0.0000e+00 - val_loss: 0.1316\n",
            "Epoch 406/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1059 - val_accuracy: 0.0000e+00 - val_loss: 0.1317\n",
            "Epoch 407/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1068 - val_accuracy: 0.0000e+00 - val_loss: 0.1317\n",
            "Epoch 408/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1088 - val_accuracy: 0.0000e+00 - val_loss: 0.1317\n",
            "Epoch 409/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1071 - val_accuracy: 0.0000e+00 - val_loss: 0.1317\n",
            "Epoch 410/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1071 - val_accuracy: 0.0000e+00 - val_loss: 0.1316\n",
            "Epoch 411/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1074 - val_accuracy: 0.0000e+00 - val_loss: 0.1317\n",
            "Epoch 412/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1065 - val_accuracy: 0.0000e+00 - val_loss: 0.1317\n",
            "Epoch 413/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1093 - val_accuracy: 0.0000e+00 - val_loss: 0.1317\n",
            "Epoch 414/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1071 - val_accuracy: 0.0000e+00 - val_loss: 0.1316\n",
            "Epoch 415/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1073 - val_accuracy: 0.0000e+00 - val_loss: 0.1317\n",
            "Epoch 416/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1050 - val_accuracy: 0.0000e+00 - val_loss: 0.1318\n",
            "Epoch 417/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1080 - val_accuracy: 0.0000e+00 - val_loss: 0.1318\n",
            "Epoch 418/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1078 - val_accuracy: 0.0000e+00 - val_loss: 0.1317\n",
            "Epoch 419/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1070 - val_accuracy: 0.0000e+00 - val_loss: 0.1316\n",
            "Epoch 420/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1063 - val_accuracy: 0.0000e+00 - val_loss: 0.1317\n",
            "Epoch 421/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1073 - val_accuracy: 0.0000e+00 - val_loss: 0.1318\n",
            "Epoch 422/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1060 - val_accuracy: 0.0000e+00 - val_loss: 0.1318\n",
            "Epoch 423/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1079 - val_accuracy: 0.0000e+00 - val_loss: 0.1318\n",
            "Epoch 424/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1080 - val_accuracy: 0.0000e+00 - val_loss: 0.1318\n",
            "Epoch 425/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1063 - val_accuracy: 0.0000e+00 - val_loss: 0.1318\n",
            "Epoch 426/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1077 - val_accuracy: 0.0000e+00 - val_loss: 0.1318\n",
            "Epoch 427/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1089 - val_accuracy: 0.0000e+00 - val_loss: 0.1317\n",
            "Epoch 428/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1085 - val_accuracy: 0.0000e+00 - val_loss: 0.1316\n",
            "Epoch 429/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1060 - val_accuracy: 0.0000e+00 - val_loss: 0.1318\n",
            "Epoch 430/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1094 - val_accuracy: 0.0000e+00 - val_loss: 0.1317\n",
            "Epoch 431/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1077 - val_accuracy: 0.0000e+00 - val_loss: 0.1318\n",
            "Epoch 432/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1064 - val_accuracy: 0.0000e+00 - val_loss: 0.1319\n",
            "Epoch 433/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1057 - val_accuracy: 0.0000e+00 - val_loss: 0.1319\n",
            "Epoch 434/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1069 - val_accuracy: 0.0000e+00 - val_loss: 0.1318\n",
            "Epoch 435/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1053 - val_accuracy: 0.0000e+00 - val_loss: 0.1318\n",
            "Epoch 436/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1084 - val_accuracy: 0.0000e+00 - val_loss: 0.1317\n",
            "Epoch 437/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1074 - val_accuracy: 0.0000e+00 - val_loss: 0.1318\n",
            "Epoch 438/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1063 - val_accuracy: 0.0000e+00 - val_loss: 0.1317\n",
            "Epoch 439/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1065 - val_accuracy: 0.0000e+00 - val_loss: 0.1317\n",
            "Epoch 440/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1060 - val_accuracy: 0.0000e+00 - val_loss: 0.1317\n",
            "Epoch 441/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1086 - val_accuracy: 0.0000e+00 - val_loss: 0.1316\n",
            "Epoch 442/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1067 - val_accuracy: 0.0000e+00 - val_loss: 0.1316\n",
            "Epoch 443/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1074 - val_accuracy: 0.0000e+00 - val_loss: 0.1317\n",
            "Epoch 444/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1054 - val_accuracy: 0.0000e+00 - val_loss: 0.1317\n",
            "Epoch 445/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1072 - val_accuracy: 0.0000e+00 - val_loss: 0.1316\n",
            "Epoch 446/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1087 - val_accuracy: 0.0000e+00 - val_loss: 0.1317\n",
            "Epoch 447/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1066 - val_accuracy: 0.0000e+00 - val_loss: 0.1318\n",
            "Epoch 448/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1100 - val_accuracy: 0.0000e+00 - val_loss: 0.1319\n",
            "Epoch 449/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1079 - val_accuracy: 0.0000e+00 - val_loss: 0.1319\n",
            "Epoch 450/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1074 - val_accuracy: 0.0000e+00 - val_loss: 0.1320\n",
            "Epoch 451/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1074 - val_accuracy: 0.0000e+00 - val_loss: 0.1319\n",
            "Epoch 452/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1061 - val_accuracy: 0.0000e+00 - val_loss: 0.1319\n",
            "Epoch 453/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1071 - val_accuracy: 0.0000e+00 - val_loss: 0.1319\n",
            "Epoch 454/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1063 - val_accuracy: 0.0000e+00 - val_loss: 0.1319\n",
            "Epoch 455/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1082 - val_accuracy: 0.0000e+00 - val_loss: 0.1319\n",
            "Epoch 456/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1079 - val_accuracy: 0.0000e+00 - val_loss: 0.1319\n",
            "Epoch 457/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1061 - val_accuracy: 0.0000e+00 - val_loss: 0.1321\n",
            "Epoch 458/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1069 - val_accuracy: 0.0000e+00 - val_loss: 0.1320\n",
            "Epoch 459/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1068 - val_accuracy: 0.0000e+00 - val_loss: 0.1319\n",
            "Epoch 460/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1065 - val_accuracy: 0.0000e+00 - val_loss: 0.1319\n",
            "Epoch 461/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1082 - val_accuracy: 0.0000e+00 - val_loss: 0.1318\n",
            "Epoch 462/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1054 - val_accuracy: 0.0000e+00 - val_loss: 0.1317\n",
            "Epoch 463/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1074 - val_accuracy: 0.0000e+00 - val_loss: 0.1317\n",
            "Epoch 464/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1077 - val_accuracy: 0.0000e+00 - val_loss: 0.1317\n",
            "Epoch 465/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1074 - val_accuracy: 0.0000e+00 - val_loss: 0.1315\n",
            "Epoch 466/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1064 - val_accuracy: 0.0000e+00 - val_loss: 0.1315\n",
            "Epoch 467/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1065 - val_accuracy: 0.0000e+00 - val_loss: 0.1315\n",
            "Epoch 468/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1056 - val_accuracy: 0.0000e+00 - val_loss: 0.1315\n",
            "Epoch 469/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1080 - val_accuracy: 0.0000e+00 - val_loss: 0.1315\n",
            "Epoch 470/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1063 - val_accuracy: 0.0000e+00 - val_loss: 0.1316\n",
            "Epoch 471/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1049 - val_accuracy: 0.0000e+00 - val_loss: 0.1316\n",
            "Epoch 472/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1100 - val_accuracy: 0.0000e+00 - val_loss: 0.1316\n",
            "Epoch 473/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.1058 - val_accuracy: 0.0000e+00 - val_loss: 0.1318\n",
            "Epoch 474/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1081 - val_accuracy: 0.0000e+00 - val_loss: 0.1319\n",
            "Epoch 475/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1073 - val_accuracy: 0.0000e+00 - val_loss: 0.1321\n",
            "Epoch 476/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1071 - val_accuracy: 0.0000e+00 - val_loss: 0.1319\n",
            "Epoch 477/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1055 - val_accuracy: 0.0000e+00 - val_loss: 0.1319\n",
            "Epoch 478/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1060 - val_accuracy: 0.0000e+00 - val_loss: 0.1319\n",
            "Epoch 479/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1066 - val_accuracy: 0.0000e+00 - val_loss: 0.1320\n",
            "Epoch 480/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1080 - val_accuracy: 0.0000e+00 - val_loss: 0.1320\n",
            "Epoch 481/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1057 - val_accuracy: 0.0000e+00 - val_loss: 0.1323\n",
            "Epoch 482/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1078 - val_accuracy: 0.0000e+00 - val_loss: 0.1323\n",
            "Epoch 483/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1065 - val_accuracy: 0.0000e+00 - val_loss: 0.1324\n",
            "Epoch 484/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1078 - val_accuracy: 0.0000e+00 - val_loss: 0.1324\n",
            "Epoch 485/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1074 - val_accuracy: 0.0000e+00 - val_loss: 0.1323\n",
            "Epoch 486/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1063 - val_accuracy: 0.0000e+00 - val_loss: 0.1323\n",
            "Epoch 487/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1074 - val_accuracy: 0.0000e+00 - val_loss: 0.1323\n",
            "Epoch 488/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1062 - val_accuracy: 0.0000e+00 - val_loss: 0.1324\n",
            "Epoch 489/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.1077 - val_accuracy: 0.0000e+00 - val_loss: 0.1323\n",
            "Epoch 490/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1067 - val_accuracy: 0.0000e+00 - val_loss: 0.1323\n",
            "Epoch 491/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1075 - val_accuracy: 0.0000e+00 - val_loss: 0.1324\n",
            "Epoch 492/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1086 - val_accuracy: 0.0000e+00 - val_loss: 0.1324\n",
            "Epoch 493/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1062 - val_accuracy: 0.0000e+00 - val_loss: 0.1323\n",
            "Epoch 494/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1071 - val_accuracy: 0.0000e+00 - val_loss: 0.1324\n",
            "Epoch 495/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1045 - val_accuracy: 0.0000e+00 - val_loss: 0.1323\n",
            "Epoch 496/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1081 - val_accuracy: 0.0000e+00 - val_loss: 0.1324\n",
            "Epoch 497/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1058 - val_accuracy: 0.0000e+00 - val_loss: 0.1323\n",
            "Epoch 498/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1067 - val_accuracy: 0.0000e+00 - val_loss: 0.1323\n",
            "Epoch 499/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1064 - val_accuracy: 0.0000e+00 - val_loss: 0.1323\n",
            "Epoch 500/500\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.1049 - val_accuracy: 0.0000e+00 - val_loss: 0.1323\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    batch_size=64,\n",
        "    epochs=500,\n",
        "    verbose=1,\n",
        "    validation_data=(x_val, y_val),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyFj3t6QNEpd"
      },
      "source": [
        "## Plot training and validation loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "TsGT-cPOAzAl",
        "outputId": "ca5eeb0b-89a7-44cf-876c-28a3a2e81feb"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(history.history[\"loss\"])\n",
        "plt.plot(history.history[\"val_loss\"])\n",
        "plt.title(\"model loss\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nn2OmjwBNLrk"
      },
      "source": [
        "## Show top 10 destinations recommendations to a user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C21qwHVTINN0",
        "outputId": "4916cf51-839e-4abb-e2d7-d19fc7d0bb90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "Showing recommendations for user: 127\n",
            "====================================\n",
            "Places with high ratings from user\n",
            "--------------------------------\n",
            "Kampung Wisata Dipowinatan : Budaya\n",
            "Pasar Beringharjo : Pusat Perbelanjaan\n",
            "Candi Ratu Boko : Budaya\n",
            "Pantai Nguluran : Bahari\n",
            "Masjid Agung Trans Studio Bandung : Tempat Ibadah\n",
            "--------------------------------\n",
            "Top 10 places recommendations\n",
            "--------------------------------\n",
            "Taman Spathodea : Taman Hiburan\n",
            "Alive Museum Ancol : Taman Hiburan\n",
            "Kampung Wisata Taman Sari : Taman Hiburan\n",
            "Bukit Bintang Yogyakarta : Taman Hiburan\n",
            "Dago Dreampark : Taman Hiburan\n",
            "Glamping Lakeside Rancabali : Taman Hiburan\n",
            "Bukit Jamur : Cagar Alam\n",
            "Obyek Wisata Goa Kreo : Cagar Alam\n",
            "Taman Keputran : Taman Hiburan\n",
            "Keraton Surabaya : Budaya\n"
          ]
        }
      ],
      "source": [
        "# call the places but places with drop attributes need to be downloaded(extracted..?) --> call \"places\" instead of movie_df\n",
        "# movie_df = pd.read_csv(movielens_dir / \"movies.csv\")\n",
        "\n",
        "# Let us get a user and see the top recommendations.\n",
        "user_id = df.User_Id.sample(1).iloc[0]\n",
        "places_visited_by_user = df[df.User_Id == user_id]\n",
        "places_not_visited = places[\n",
        "    ~places[\"Place_Id\"].isin(places_visited_by_user.Place_Id.values)\n",
        "][\"Place_Id\"]\n",
        "places_not_visited = list(\n",
        "    set(places_not_visited).intersection(set(place2place_encoded.keys()))\n",
        ")\n",
        "places_not_visited = [[place2place_encoded.get(x)] for x in places_not_visited]\n",
        "user_encoder = user2user_encoded.get(user_id)\n",
        "user_place_array = np.hstack(\n",
        "    ([[user_encoder]] * len(places_not_visited), places_not_visited)\n",
        ")\n",
        "ratings = model.predict(user_place_array).flatten()\n",
        "top_ratings_indices = ratings.argsort()[-10:][::-1]\n",
        "recommended_place_ids = [\n",
        "    place_encoded2place.get(places_not_visited[x][0]) for x in top_ratings_indices\n",
        "]\n",
        "\n",
        "print(\"Showing recommendations for user: {}\".format(user_id))\n",
        "print(\"====\" * 9)\n",
        "print(\"Places with high ratings from user\")\n",
        "print(\"----\" * 8)\n",
        "top_places_user = (\n",
        "    places_visited_by_user.sort_values(by=\"rating\", ascending=False)\n",
        "    .head(5)\n",
        "    .Place_Id.values\n",
        ")\n",
        "place_df_rows = places[places[\"Place_Id\"].isin(top_places_user)]\n",
        "for row in place_df_rows.itertuples():\n",
        "    print(row.Place_Name, \":\", row.Category)\n",
        "\n",
        "print(\"----\" * 8)\n",
        "print(\"Top 10 places recommendations\")\n",
        "print(\"----\" * 8)\n",
        "recommended_places = places[places[\"Place_Id\"].isin(recommended_place_ids)]\n",
        "for row in recommended_places.itertuples():\n",
        "    print(row.Place_Name, \":\", row.Category)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "# Save the model architecture to a h5 file\n",
        "model.save('model_destinatik_v1.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Serialize model architecture to JSON\n",
        "model_json = model.to_json()\n",
        "\n",
        "# Modify the model configuration to include additional parameters\n",
        "model_config = json.loads(model_json)\n",
        "model_config['config']['num_users'] = num_users\n",
        "model_config['config']['num_places'] = num_places\n",
        "model_config['config']['embedding_size'] = EMBEDDING_SIZE\n",
        "\n",
        "# Save the modified model configuration to JSON\n",
        "with open(\"model_destinatik_v1.json\", \"w\") as json_file:\n",
        "    json.dump(model_config, json_file)\n",
        "\n",
        "# # Save the model architecture to a JSON file\n",
        "# model_json = model.to_json()\n",
        "# with open(\"model_destinatik_v1.json\", \"w\") as json_file:\n",
        "#     json_file.write(model_json)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load the model back"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Layer count mismatch when loading weights from file. Model expected 0 layers, found 4 saved layers.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[76], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m custom_objects \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecommenderNet\u001b[39m\u001b[38;5;124m\"\u001b[39m: create_recommender_net}\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Load the entire model from a HDF5 file\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_destinatik_v1.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.conda/envs/main-ml/lib/python3.11/site-packages/keras/src/saving/saving_api.py:183\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[1;32m    177\u001b[0m         filepath,\n\u001b[1;32m    178\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[1;32m    180\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[1;32m    181\u001b[0m     )\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m--> 183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_h5_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model_from_hdf5\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    190\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    191\u001b[0m     )\n",
            "File \u001b[0;32m~/.conda/envs/main-ml/lib/python3.11/site-packages/keras/src/legacy/saving/legacy_h5_format.py:138\u001b[0m, in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    133\u001b[0m     model \u001b[38;5;241m=\u001b[39m saving_utils\u001b[38;5;241m.\u001b[39mmodel_from_config(\n\u001b[1;32m    134\u001b[0m         model_config, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects\n\u001b[1;32m    135\u001b[0m     )\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# set weights\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m     \u001b[43mload_weights_from_hdf5_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_weights\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcompile\u001b[39m:\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# instantiate optimizer\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     training_config \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mattrs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_config\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/.conda/envs/main-ml/lib/python3.11/site-packages/keras/src/legacy/saving/legacy_h5_format.py:357\u001b[0m, in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, model)\u001b[0m\n\u001b[1;32m    355\u001b[0m layer_names \u001b[38;5;241m=\u001b[39m filtered_layer_names\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(layer_names) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(filtered_layers):\n\u001b[0;32m--> 357\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    358\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer count mismatch when loading weights from file. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    359\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(filtered_layers)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m layers, found \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    360\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(layer_names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m saved layers.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    361\u001b[0m     )\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(layer_names):\n\u001b[1;32m    364\u001b[0m     g \u001b[38;5;241m=\u001b[39m f[name]\n",
            "\u001b[0;31mValueError\u001b[0m: Layer count mismatch when loading weights from file. Model expected 0 layers, found 4 saved layers."
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# # Define the custom objects dictionary\n",
        "# custom_objects = {\"RecommenderNet\": RecommenderNet}\n",
        "\n",
        "# Define a function to create an instance of RecommenderNet with required arguments\n",
        "def create_recommender_net(**kwargs):\n",
        "    return RecommenderNet(num_users, num_places, EMBEDDING_SIZE, **kwargs)\n",
        "# def create_recommender_net(**kwargs):\n",
        "#     return RecommenderNet(**kwargs)\n",
        "\n",
        "# Define the custom objects dictionary with the function\n",
        "custom_objects = {\"RecommenderNet\": create_recommender_net}\n",
        "\n",
        "# Load the entire model from a HDF5 file\n",
        "loaded_model = load_model('model_destinatik_v1.h5', custom_objects=custom_objects)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.models import model_from_json\n",
        "\n",
        "# Load the model architecture from a JSON file\n",
        "with open(\"model_destinatik_v1.json\", \"r\") as json_file:\n",
        "    model_json = json_file.read()\n",
        "\n",
        "loaded_model = model_from_json(model_json)\n",
        "\n",
        "# Load the weights into the new model\n",
        "# loaded_model.load_weights('model_destinatik_v1.h5')\n",
        "\n",
        "# Compile the loaded model (necessary if you plan to further train or evaluate it)\n",
        "# loaded_model.compile(\n",
        "#     loss=keras.losses.MeanSquaredError(),\n",
        "#     optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
